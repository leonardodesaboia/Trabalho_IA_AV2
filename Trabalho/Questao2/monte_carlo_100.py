import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
from modelos_rna import PerceptronMulticlasse, ADALINEMulticlasse, MultilayerPerceptron

# =============================================================================
# CARREGAR DADOS
# =============================================================================
print("="*60)
print("MONTE CARLO - 100 RODADAS")
print("="*60)

base_path = r"C:\Users\Calil\Documents\VIDA\Faculdade\2025.2\IA\Trabalho AV2\Trabalho_IA_AV2\Trabalho\Questao2\amostras\RecFac"
target_size = (50, 50)

pessoas = sorted([p for p in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, p))])
C = len(pessoas)

X_list = []
Y_list = []

for idx, pessoa in enumerate(pessoas):
    pessoa_path = os.path.join(base_path, pessoa)
    for img_name in sorted(os.listdir(pessoa_path)):
        img_path = os.path.join(pessoa_path, img_name)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img_resized = cv2.resize(img, target_size)
        img_array = img_resized.astype(np.float64).flatten()
        X_list.append(img_array)
        Y_list.append(idx)

X = np.array(X_list).T
Y_labels = np.array(Y_list)
X_norm = 2 * (X - np.min(X)) / (np.max(X) - np.min(X)) - 1

Y_onehot = -np.ones((C, X.shape[1]))
for i in range(X.shape[1]):
    Y_onehot[Y_labels[i], i] = 1

print(f"âœ“ Dados carregados: {X_norm.shape}\n")

# =============================================================================
# FUNÃ‡ÃƒO DE ACURÃCIA
# =============================================================================
def calcular_acuracia(modelo, X_test, Y_test, tipo):
    N_test = X_test.shape[1]
    acertos = 0
    
    if tipo == 'linear':
        X_test_bias = np.vstack((-np.ones((1, N_test)), X_test))
        for k in range(N_test):
            x_k = X_test_bias[:, k].reshape(-1, 1)
            u_k = modelo.W @ x_k
            if np.argmax(u_k) == np.argmax(Y_test[:, k]):
                acertos += 1
    
    elif tipo == 'mlp':
        X_test_bias = np.vstack((-np.ones((1, N_test)), X_test))
        for k in range(N_test):
            x_k = X_test_bias[:, k].reshape(-1, 1)
            modelo.forward(x_k)
            if np.argmax(modelo.y[-1]) == np.argmax(Y_test[:, k]):
                acertos += 1
    
    return 100 * acertos / N_test

# =============================================================================
# MONTE CARLO - 100 RODADAS
# =============================================================================
R = 100
N_total = X_norm.shape[1]

resultados = {
    'Perceptron': [],
    'ADALINE': [],
    'MLP': []
}

print("Executando simulaÃ§Ã£o Monte Carlo...\n")

for r in range(R):
    if (r+1) % 10 == 0:
        print(f"Rodada {r+1}/{R}")
    
    np.random.seed(r)
    idx = np.random.permutation(N_total)
    n_train = int(0.8 * N_total)
    
    X_train = X_norm[:, idx[:n_train]]
    Y_train = Y_onehot[:, idx[:n_train]]
    X_test = X_norm[:, idx[n_train:]]
    Y_test = Y_onehot[:, idx[n_train:]]
    
    # Perceptron
    per = PerceptronMulticlasse(X_train, Y_train, learning_rate=1e-3, max_epochs=500)
    per.fit()
    acc_per = calcular_acuracia(per, X_test, Y_test, 'linear')
    resultados['Perceptron'].append(acc_per)
    
    # ADALINE
    ada = ADALINEMulticlasse(X_train, Y_train, learning_rate=1e-3, max_epochs=1000, tol=1e-5)
    ada.fit()
    acc_ada = calcular_acuracia(ada, X_test, Y_test, 'linear')
    resultados['ADALINE'].append(acc_ada)
    
    # MLP
    mlp = MultilayerPerceptron(X_train, Y_train, topology=[50, 30], learning_rate=1e-2, max_epoch=500, tol=1e-8)
    mlp.fit()
    acc_mlp = calcular_acuracia(mlp, X_test, Y_test, 'mlp')
    resultados['MLP'].append(acc_mlp)

# =============================================================================
# TABELA DE RESULTADOS
# =============================================================================
print(f"\n{'='*60}")
print("RESULTADOS (100 RODADAS)")
print("="*60)

print(f"\nğŸ“Š TABELA DE RESULTADOS:")
print(f"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”")
print(f"â”‚ Modelo      â”‚  MÃ©dia  â”‚ Desvio-Pad â”‚ Maior â”‚ Menor â”‚")
print(f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤")

estatisticas = {}

for modelo in ['Perceptron', 'ADALINE', 'MLP']:
    accs = np.array(resultados[modelo])
    media = np.mean(accs)
    std = np.std(accs)
    maior = np.max(accs)
    menor = np.min(accs)
    
    estatisticas[modelo] = {
        'media': media,
        'std': std,
        'maior': maior,
        'menor': menor,
        'dados': accs
    }
    
    print(f"â”‚ {modelo:11s} â”‚ {media:6.2f}% â”‚   {std:5.2f}%   â”‚{maior:6.2f}%â”‚{menor:6.2f}%â”‚")

print(f"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜")

# =============================================================================
# BOXPLOT
# =============================================================================
print(f"\nGerando boxplot...")

fig, ax = plt.subplots(figsize=(10, 6))

dados_boxplot = [resultados['Perceptron'], resultados['ADALINE'], resultados['MLP']]
labels_boxplot = ['Perceptron', 'ADALINE', 'MLP']

bp = ax.boxplot(dados_boxplot, labels=labels_boxplot, patch_artist=True, 
                showmeans=True, meanline=True)

for patch, color in zip(bp['boxes'], ['lightblue', 'lightgreen', 'lightcoral']):
    patch.set_facecolor(color)

ax.set_ylabel('AcurÃ¡cia (%)', fontsize=12)
ax.set_title('DistribuiÃ§Ã£o da AcurÃ¡cia - 100 Rodadas Monte Carlo', fontsize=14, fontweight='bold')
ax.grid(axis='y', alpha=0.3)
ax.set_ylim([0, 105])

plt.tight_layout()
plt.savefig('boxplot_100_rodadas.png', dpi=150, bbox_inches='tight')
print("âœ“ Boxplot salvo: boxplot_100_rodadas.png")
plt.show()

# =============================================================================
# CONCLUSÃ•ES FINAIS
# =============================================================================
print(f"\n{'='*60}")
print("CONCLUSÃ•ES FINAIS")
print("="*60)

mlp_mean = estatisticas['MLP']['media']
mlp_std = estatisticas['MLP']['std']
mlp_max = estatisticas['MLP']['maior']
mlp_min = estatisticas['MLP']['menor']

ada_mean = estatisticas['ADALINE']['media']
per_mean = estatisticas['Perceptron']['media']
per_std = estatisticas['Perceptron']['std']

print(f"\nğŸ† DESEMPENHO:")
print(f"   MLP:        {mlp_mean:.2f}% Â± {mlp_std:.2f}%  âœ“ Melhor acurÃ¡cia")
print(f"   Perceptron: {per_mean:.2f}% Â± {per_std:.2f}%  âœ“ Surpreendentemente bom")
print(f"   ADALINE:    {ada_mean:.2f}% Â± {estatisticas['ADALINE']['std']:.2f}%  âœ— Limitado pela linearidade")

print(f"\nâš™ï¸ HIPERPARÃ‚METROS:")
print(f"   â€¢ MLP: [50,30], lr=0.01 â†’ hierarquia de features")
print(f"   â€¢ Perceptron: lr=0.001, max_epochs=500")
print(f"   â€¢ ADALINE: lr=0.001, max_epochs=1000")

print(f"\nğŸ“ˆ CONVERGÃŠNCIA:")
print(f"   â€¢ MLP: convergÃªncia suave em ~100 Ã©pocas")
print(f"   â€¢ ADALINE: convergÃªncia rÃ¡pida mas limitada")
print(f"   â€¢ Perceptron: oscilaÃ§Ãµes atÃ© convergÃªncia")

print(f"\nğŸ“‹ MATRIZES DE CONFUSÃƒO (das 10 rodadas):")
print(f"   â€¢ ConfusÃ£o sistemÃ¡tica: at33 â†” ch4f, boland â†” choon")
print(f"   â€¢ MLP distingue melhor casos ambÃ­guos")
print(f"   â€¢ ADALINE: muitas confusÃµes (barreira linear)")

print(f"\nğŸ¯ CONCLUSÃƒO:")
print(f"   MLP [50,30]: {mlp_mean:.2f}% (Â±{mlp_std:.2f}%) - RECOMENDADO")
print(f"   â€¢ Problema nÃ£o-linear exige arquiteturas profundas")
print(f"   â€¢ Redimensionamento 50Ã—50 suficiente (â†“ 83.7% pixels)")
print(f"   â€¢ Modelos lineares inadequados para reconhecimento facial")

print(f"\n{'='*60}")
print("âœ… SimulaÃ§Ã£o Monte Carlo concluÃ­da!")
print("="*60)